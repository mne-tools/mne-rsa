{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Tutorial part 3: statistical analysis of group-level RSA results\n\nIn this tutorial, we'll dive into cluster-based permutation testing for group-level\nstatistical analysis.\n\nThe statistical test is described in [Maris & Oostenveld, 2007](https://doi.org/10.1016/j.jneumeth.2007.03.024)_. This functionality is not part of\nthe MNE-RSA package, but rather MNE-Python, but it is a large part of a proper RSA\nanalysis so I figures any decent RSA tutorial should cover this.\n\nCluster-based permutation testing is becoming the standard \u201cgo-to\u201d method for testing\nfor significant differences between experimental conditions in MEG and EEG studies.\nHowever, applying the technique correctly is not always straightforward and there are a\nlot of caveats to beware of. On top of this, the API of MNE-Python regarding these tests\ncould use a bit more work. (If you are inspired by this tutorial, could you [lend a hand](https://github.com/mne-tools/mne-python/issues/4859)_ with this? \u2764)\n\n# The purpose of cluster-based permutation testing\n\nWhen exploring differences between conditions, a good first step is to perform separate\nt-tests for each channel/sourcepoint/timepoint and visualize them. While this gives you\na good feel of where and when significant differences may occur, one cannot always make\nsolid statistical inferences based on these values. Cluster-based permutation testing is\ndesigned to solve two problems that arise when using mass t-tests:\n\n1. The multiple-comparisons problem: solved by using a cluster-based\n   statistic\n2. The non-Gaussian data problem: solved by using random permutations\n\nThe solutions to these problems come at a hefty price though: the test can only infer\nthe data is different between conditions. **The test can not be used to infer when and\nwhere there is a significant difference.** Researchers get this wrong a lot. The\nFieldtrip manual even has a [dedicated page about this](https://www.fieldtriptoolbox.org/faq/how_not_to_interpret_results_from_a_cluster-based_permutation_test)_\nwhich I encourage you to read.\n\nNow that I\u2019ve scared you enough, let\u2019s do this!\n\nIn the cell below, update the ``data_path`` variable to point to where you have\nextracted the\n```rsa-data.zip`[](https://github.com/wmvanvliet/neuroscience_tutorials/releases/download/2/rsa-data.zip)_\nfile to.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# ruff: noqa: E402\n# sphinx_gallery_thumbnail_number=2\n\nimport mne\n\nmne.set_log_level(\"warning\")  # Make the output less verbose\n\n# Set this to where you've extracted `rsa-data.zip` to\ndata_path = \"data\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cluster permutation testing on a single channel\n\nIn the classic EEG event-related potential (ERP) literature, statistical\ntesting between two conditions was done by first identifying one or more\nsensors and stretches of time that seem likely to hold a significant\ndifference, then averaging the signal across those sensors and time\nregion, followed by a single t-test or ANOVA test. Time would tell\nwhether the chosen channels and time region would replicate across\nstudies.\n\nLet\u2019s do this for our sensor-level RSA result that we obtained in\n`tut-sensor-level`. I\u2019ve ran the same analysis across multiple subjects and\nplaced it in the ``group_analysis`` subfolder of the data package you\u2019ve downloaded.\nExecuting the call below will load them.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import mne\n\nsubjects = [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19]\n\n# RSA against the RDM based on the pixels in each image\nrsa_pixels = [\n    mne.read_evokeds(\n        f\"{data_path}/group_analysis/sub-{subject:02d}-rsa-ave.fif\", condition=\"pixels\"\n    )\n    for subject in subjects\n]\n\n# RSA against the RDM based on the FaceNet embeddings of each image\nrsa_facenet = [\n    mne.read_evokeds(\n        f\"{data_path}/group_analysis/sub-{subject:02d}-rsa-ave.fif\", condition=\"facenet\"\n    )\n    for subject in subjects\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``rsa_pixels`` and ``rsa_facenet`` are now lists of :class:`mne.Evoked` objects. Here\nare the first 5 of them:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rsa_pixels[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Every :class:`mne.Evoked`` object has data defined for a single channel, for the time\nregion 0 \u2013 0.9 seconds. The cell below compares the grand averages for pixels versus\nFaceNet and gives the 95% confidence intervals for the means:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mne.viz.plot_compare_evokeds(\n    dict(pixels=rsa_pixels, facenet=rsa_facenet),\n    picks=0,\n    show_sensors=0,\n    ylim=dict(misc=[-0.02, 0.15]),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the above plot, there might be a significant difference very\nearly on: 0 \u2013 0.16 seconds. Let\u2019s run a t-test in this time-window.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom scipy.stats import ttest_rel\n\n# Construct arrays with the data of all participants combined\ndata_pixels = np.array(\n    [ev.data[0] for ev in rsa_pixels]\n)  # shape: 16 x 199 (participants x timepoints)\ndata_facenet = np.array(\n    [ev.data[0] for ev in rsa_facenet]\n)  # shape: 16 x 199 (participants x timepoints)\n\n# Time region we are interested in\ntmin, tmax = 0, 0.16  # seconds\n\n# Convert tmin/tmax to sample indices\ntmin, tmax = np.searchsorted(rsa_pixels[0].times, [tmin, tmax])\n\n# Average the data across the time window\ndata_pixels_avg = data_pixels[:, tmin:tmax].mean(axis=1)\ndata_facenet_avg = data_facenet[:, tmin:tmax].mean(axis=1)\n\n# Perform the t-test\ntval, pval = ttest_rel(data_pixels_avg, data_facenet_avg)\n\nassert np.isscalar(tval), \"We want a single t-value\"\nassert np.isscalar(pval), \"We want a single p-value\"\nassert pval < 0.05, f\"p-value is not significant {pval=}\"\n\nprint(f\"{tval=}, {pval=}   Looking great! \ud83d\ude0a\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# The \u201ccluster\u201d part of cluster permutation tests\n\nIn essence, the permutation cluster test automates what we\u2019ve just done\nabove, but with a twist that we will get to later.\n\nFirst, it must determine \u201cclusters\u201d, i.e.\u00a0regions of interest where\nthere might be a significant difference between the conditions. We\neyeballed this based on the confidence interval of the mean, but the\nalgorithm must use some form of automated function. We can specify the\nfunction that the algorithm should use, but it comes with a useful\ndefault: a t-test: :func:`mne.stats.ttest_1samp_no_p`\n\n.. warning\n   The initial t-test (or whatever stat function you chose) is just to form clusters,\n   it is not used to determine significance!\n\nLet\u2019s do this step manually first, so you get an understanding what is going on: -\nFirst, we do the t-test for every timepoint - This is a t-test against 0. To perform a\npaired t-test, we test ``data_pixels - data_facenet`` - Then, we set a threshold -\nEverything above the threshold becomes a cluster - We compute the sum of all the\nt-values inside the cluster\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nfrom mne.stats import ttest_1samp_no_p\n\ntvals = ttest_1samp_no_p(data_pixels - data_facenet)\n\n\n# Plot the t-values and form a cluster\ndef plot_cluster(tvals, threshold, data_cond1, data_cond2):\n    \"\"\"Plot a cluster.\"\"\"\n    times = rsa_pixels[0].times\n\n    # Make the cluster\n    cluster = np.where(tvals > threshold)[0]\n\n    # This is an important statistec: the sum of all t-values in the cluster\n    cluster_tvals_sum = tvals[cluster].sum()\n\n    # Show the t-values and how the cluster is determined\n    plt.figure(figsize=(8, 4))\n    plt.plot(times, tvals, label=\"t-values\")\n    plt.axhline(0, color=\"black\", linewidth=1)\n    plt.axhline(2, color=\"black\", linestyle=\"--\", linewidth=1, label=\"threshold\")\n    plt.fill_between(\n        times[cluster],\n        tvals[cluster],\n        threshold * np.ones(len(cluster)),\n        color=\"C1\",\n        alpha=0.5,\n        label=\"cluster\",\n    )\n    plt.legend()\n    plt.xlabel(\"Time samples\")\n    plt.ylabel(\"t-value\")\n    return cluster_tvals_sum\n\n\ncluster_tvals_sum = plot_cluster(\n    tvals, threshold=2, data_cond1=data_pixels, data_cond2=data_facenet\n)\nprint(f\"Sum of t-values in the cluster: {cluster_tvals_sum:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the figure above, a threshold value of ``2`` seems to obtain a reasonable\ncluster. We could have chosen a different threshold, and there is no reason to choose\na threshold that corresponds to some p-value, other than perhaps providing a sensible\ndefault value. The statistical function and the threshold used to form clusters are\ncompletely up to the researcher. The idea here is to use your domain knowledge to\nincrease statistical power: when clusters \u201cmake sense\u201d regarding to what we know about\nthe experimental setup and how MEG data behaves, we are likely to obtain better\np-values in the end.\n\n## The \u201cpermutation\u201d part of the cluster permutation test\n\nNow that we have our cluster, we can \u201cpermute\u201d it to find what random clusters looks\nlike. In order to generate random clusters, we mix up the class labels. Read the code\nin the cell below carefully to find out how this is done:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Throw the data onto one big pile\nbig_pile = np.vstack((data_pixels, data_facenet))\n\n# Shuffle the rows. This is what a \"random permutation\" means.\nnp.random.shuffle(big_pile)\n\n# Divide again into the \"pixels\" and \"facenet\" conditions\npermuted_pixels, permuted_facenet = big_pile[: len(subjects)], big_pile[len(subjects) :]\n\n# Compute t-values, which should be nice and low\npermuted_tvals = ttest_1samp_no_p(permuted_pixels - permuted_facenet)\n\n# See what the clusters look like now\npermuted_cluster_tvals_sum = plot_cluster(\n    permuted_tvals, threshold=2, data_cond1=permuted_pixels, data_cond2=permuted_facenet\n)\nprint(\"Sum of t-values in cluster:\", permuted_cluster_tvals_sum.round(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can run the cell above multiple times to see what different permutations look\nlike. If it is very rare that we get a cluster with larger max t-value than the one we\nfound in the original data, we can say that there is a significant difference in the\noriginal data. Finally, the percentage of times you find a larger max t-value in the\nrandomly permuted data is your p-value.\n\nAnd that is the cluster permutation test!\n\nSo, with all of this in mind, we can now use the MNE-Python\n:func:`mne.stats.permutation_cluster_1samp_test`\nto perform everything we have done above in a single line of code. When\nstudying the line of code, keep the following in mind:\n\n- Read the documentation of :func:`mne.stats.permutation_cluster_1samp_test` first!\n- The first parameter, ``X`` is your data matrix (``n_participants x n_times``). Since\n  we are using paired t-tests to define clusters, you need to set this to\n  ``data_pixels - data_facenet`` like we did before\n- The threshold to form clusters is ``2`` like we used before - We set ``tail=1`` to\n  only look for positive t-values to mimic what we did before. You can also experiment\n  with ``-1`` and ``0`` to look for clusters with negative t-values or both positive\n  and negative.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from mne.stats import permutation_cluster_1samp_test\n\nt_obs, clusters, pvals, H0 = permutation_cluster_1samp_test(\n    X=data_pixels - data_facenet, threshold=2, tail=1\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Executing the cell below will explain what all the return values mean:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "times = rsa_pixels[0].times\nprint(\n    f\"t_obs (an array of length {len(t_obs)}) contains the initial t-values that are \"\n    \"used to create the clusters.\"\n)\nprint(\n    f\"clusters (a list of length {len(clusters)}) contains for each cluster, the \"\n    \"indices in the data array that are part of the cluster.\"\n)\nprint(\n    f\"pvals (an array of length {len(pvals)}) contains for each cluster a p-value, \"\n    \"more about this later.\"\n)\nprint(\n    f\"H0 (an array of length {len(H0)}) contains the largest \"\n    \"`permuted_cluster_tvals_sum` found in each random permutation.\"\n)\nprint()\nprint(f\"The cluster permutation test found {len(clusters)} clusters.\")\nfor i, cluster in enumerate(clusters):\n    print(\n        f\"Cluster {i}: {times[cluster[0].min()]:.3f}-{times[cluster[0].max()]:.3f} \"\n        \"seconds.\"\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Computing the p-value\n\nDepending on the value of ``tail`` you used in your call to\n:func:`mne.stats.permutation_cluster_1samp_test` you have either 1, 2, or 3 clusters.\nThe clusters that your test found each have an associated p-value.\n\n- If the sum-of-t-values for the cluster was **positive**, then the p-value is the\n  fraction of random permutations that produced a cluster which a sum-of-t-values that\n  was equal or **greater**\n- If the sum-of-t-values for the cluster was **negative**, then the p-value is the\n  fraction of random permutations that produced a cluster which a sum-of-t-values that\n  was equal or **smaller**\n\nTo understand this better, lets use the ``t_obs``, ``clusters`` and ``H0`` return\nvalues that you produced above to compute this p-value ourselves to test our knowledge\nof what these return values mean. We will:\n\n- Loop over all the clusters you found\n- Determine the ``sum_of_t_values`` inside the cluster\n- Compute the fraction of ``H0`` whose absolute value is equal or larger than the\n  absolute ``sum_of_t_values``\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"The cluster p-values should be:\\t{pvals}\")\nour_pvals = [(H0 >= t_obs[cluster].sum()).mean() for cluster in clusters]\nprint(f\"Our manually computed cluster p-values are:\\t{our_pvals}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interpreting the p-value\n\nNow comes the twist that I mentioned in the beginning. The final part of the cluster\npermutation test is that you use the **smallest** cluster p-value as final outcome of\nthe test. You might be tempted to judge the significance of each cluster separately\nbased on its associated p-value, but that would be statistically incorrect.\n\n.. warning\n   The data inside a cluster was compared against random permutations of the dataset\n   as a whole, not just the data inside the cluster. Hence, the test does not say\n   whether a cluster by itself is statistically significant or not. The cluster\n   permutation test only tells you whether the distribution of the data **as a\n   whole** is significantly different between conditions. This is the price you pay\n   to avoid the multiple comparisons problem.\n\nSo what can you do? [Sassenhagen & Draschkow\n2019](https://onlinelibrary.wiley.com/doi/10.1111/psyp.13335)_ offer\nsome good advice. Personally, I would go for something like:\n\n    The cluster-based permutation test revealed a significant difference\n    between the conditions (p=SMALLEST_P_VALUE). This result was mostly\n    driven by clusters at X (CLUSTER_PVAL) and Y (CLUSTER_PVAL), which\n    correspond roughly to DESCRIPTION_OF_ROIS\u201d.\n\n# Clusters across space and time\n\nThe formation of clusters becomes a bit more tricky in the case of\n:class:`mne.SourceEstimate` objects, where data is defines across vertices in space as\nwell as samples in time.\n\nIn this case, the first order of business is to morph everything to a template brain,\nso that the vertices are aligned. This is common practice in MEG group analysis, so\nI\u2019m not going to cover that process in this tutorial.\n\nInstead, I have run the spatio-temporal RSA analysis that we did\n`tut-source-level` across multiple subjects and placed the results in the\n``group_analysis`` folder of your data package. Let\u2019s load them and see if we can run\na spatio-temporal cluster-based permutation test (quite a mouthful).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from mne import read_source_estimate\n\nstc_pixels = [\n    read_source_estimate(\n        f\"{data_path}/group_analysis/sub-{subject:02d}-rsa-pixels-morphed\"\n    )\n    for subject in subjects\n]\nstc_facenet = [\n    read_source_estimate(\n        f\"{data_path}/group_analysis/sub-{subject:02d}-rsa-facenet-morphed\"\n    )\n    for subject in subjects\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, ``stc_pixels`` and ``stc_facenet`` are two lists containing the\n:class:`mne.SourceEstimate`\u2019s for all subjects. Here are 5 of them:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "stc_pixels[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let\u2019s proceed as before by first looking at the difference between the\nmeans of the two conditions. A neat feature of the\n:class:`mne.SourceEstimate`\nclass is that it supports common math operations such as ``+``, ``-``,\n``*`` and ``/``. For example, computing the difference between the\n``pixels`` and ``facenet`` RSA results of the first subject can simply\nbe computed as ``stc_diff = stc_pixels[0] - stc_facenet[0]``. In the\ncell below, we compute the difference between the two conditions in a\npairwise manner for each subject, then compute the mean across the\npairwise differences. If you want a nice elegant way to write this,\nremember that the\n```zip()`[](https://docs.python.org/3/library/functions.html#zip)_\nfunction exists.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "stc_pairwise_diff = np.mean(\n    [stc1 - stc2 for stc1, stc2 in zip(stc_pixels, stc_facenet)]\n)\n\n# Visualize the result.\nstc_pairwise_diff.plot(\n    \"fsaverage\",\n    subjects_dir=f\"{data_path}/freesurfer\",\n    hemi=\"both\",\n    initial_time=0.121,\n    views=\"caudal\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The figure shows us clear differences between the pixel versus FaceNet\nRSA scores across the visual cortex.\n\nLet\u2019s explore this difference with a t-value map. In order to compute t-values, we\nneed to pull the data out of the :class:`mne.SourceEstimate` objects. As before, since\nwe have a within-subject contrast between the two conditions, we want to perform\npairwise tests. So, as a first step, create a data array ``X`` of shape\n``(n_participants x n_vertices x n_times)`` where each slice ``i`` along the first\ndimension is the difference between ``stc_pixels[i].data - stc_facenet[i].data``. The\nnext step is running ``X`` through the :func:`mne.stats.ttest_1samp_no_p` function to\nobtain t-values.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from mne.stats import ttest_1samp_no_p\n\nX = np.array([stc1.data - stc2.data for stc1, stc2 in zip(stc_pixels, stc_facenet)])\ntvals = ttest_1samp_no_p(X)\n\n# Some sanity checks for our result\nassert X.shape == (16, 20484, 109), \"Your `X` array has the wrong shape. \ud83e\udd14\"\nassert -0.17 < X.min() < -0.16, \"Your `X` array does not have the correct values. \ud83e\udd14\"\nassert 0.29 < X.max() < 0.30, \"Your `X` array does not have the correct values. \ud83e\udd14\"\n\nassert tvals.shape == (20484, 109), \"Your `tvals` array has the wrong shape. \ud83e\udd14\"\nassert (\n    -6.6 < tvals.min() < -6.5\n), \"Your `tvals` array does not have the correct values. \ud83e\udd14\"\nassert (\n    7.4 < tvals.max() < 7.5\n), \"Your `tvals` array does not have the correct values. \ud83e\udd14\"\n\nprint(\"All good! \ud83d\ude0a\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can pack the ``tvals`` into a new :class:`mne.SourceEstimate` object in order\nto visualize them:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "stc_tvals = mne.SourceEstimate(\n    data=tvals,\n    vertices=stc_pixels[0].vertices,\n    tmin=stc_pixels[0].tmin,\n    tstep=stc_pixels[0].tstep,\n    subject=\"fsaverage\",\n)\nstc_tvals.plot(\n    \"fsaverage\",\n    subjects_dir=f\"{data_path}/freesurfer\",\n    hemi=\"both\",\n    initial_time=0.121,\n    views=\"caudal\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From this figure, it seems that setting a threshold of ``4`` may result in useful\nclusters for our cluster-based permutation test. The function to perform the test in\nboth space and time is called :func:`mne.stats.spatio_temporal_cluster_1samp_test`\n\nBut wait! Before you go and run the test, there\u2019s two things we need to\ntake care of.\n\n.. warning\n   The order of the dimensions of ``X``, namely ``(n_subjects x n_vertices x\n   n_samples)`` is not how :func:`mne.stats.spatio_temporal_cluster_1samp_test` wants\n   them. The function wants them as ``(n_subjects x n_samples x n_vertices)``. This is\n   super unintuitive and everybody I know has gotten this wrong at least once. So,\n   first we need to do ``X.transpose(0, 2, 1)`` to get the dimensions in the proper\n   order. Please consider [helping us to improve the API](https://github.com/mne-tools/mne-python/issues/4859)_ and get this fixed.\n\nThe other thing to keep in mind is that in order to form clusters across the cortex,\nwe need to make sure that only neighbouring vertices are part of the same cluster.\nThis is a similar problem as we faced when computing searchlight patches in space\nduring our RSA analysis. The solution is found within the :class:`mne.SourceSpaces`\nobject that keeps track of the distances between source points. Since all of our data\nhas been morphed to the ``fsaverage`` template brain, we need to load the\n:class:`mne.SourceSpaces` object for that brain. Then, we can compute the spatial\nadjacency matrix from the :class:`mne.SourceSpaces` object through the\n:func:`mne.spatial_src_adjacency` function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "src = mne.read_source_spaces(\n    f\"{data_path}/freesurfer/fsaverage/bem/fsaverage-ico-5-src.fif\"\n)\nadj = mne.spatial_src_adjacency(src)\n\nassert adj.shape == (20484, 20484), \"You've `adj` seems to have the wrong shape. \ud83e\udd14\"\nprint(\"All good! \ud83d\ude0a\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now it\u2019s time to run the big spatio-temporal cluster-based permutation test! `Read its\ndocumentation first (:func:`mne.stats.spatio_temporal_cluster_1samp_test`) and then go\nfor it!\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from mne.stats import spatio_temporal_cluster_1samp_test\n\nt_obs, clusters, pvals, H0 = spatio_temporal_cluster_1samp_test(\n    X.transpose(0, 2, 1), threshold=4, tail=1, adjacency=adj, n_jobs=-1, verbose=True\n)\n\n# What is the smallest cluster p-value that we found? Was it significant? (p < 0.05?)\nprint(\"Smallest p-value:\", pvals.min())\nif pvals.min() < 0.05:\n    print(\"It was significant! \ud83c\udf89\")\nelse:\n    print(\"It was not significant \ud83e\udd14\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MNE-Python comes with a function called :func:`mne.stats.summarize_clusters_stc` that\nshows the spatial extent of the clusters:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from mne.stats import summarize_clusters_stc\n\nstc_all_cluster_vis = summarize_clusters_stc(\n    (t_obs, clusters, pvals, H0),  # output of spatio_temporal_cluster_1samp_test\n    tstep=stc_pixels[0].tstep,  # difference in time between two time samples\n    vertices=stc_pixels[0].vertices,  # vertex numbers\n    subject=\"fsaverage\",  # FreeSurfer subject whose brain to draw\n    p_thresh=0.05,  # Only show clusters with an associated p-value below this threshold\n)\n\n# Plot the summary created by summarize_clusters_stc\nstc_all_cluster_vis.plot(\n    hemi=\"both\",\n    views=\"ventral\",\n    subjects_dir=f\"{data_path}/freesurfer\",\n    time_label=\"temporal extent (ms)\",\n    clim=dict(kind=\"value\", pos_lims=[0, 0.01, 0.11]),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the figure above, the first time point shows all the clusters and the\nsubsequent timepoints show each cluster individually. The colors\nindicate the extent of the cluster in time (=number of samples).\n\n\ud83c\udf89 CONGRATULATIONS \ud83c\udf89 You\u2019ve reached the end of this tutorial series and\nmastered the spatio-temporal cluster-based permutation test!\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}