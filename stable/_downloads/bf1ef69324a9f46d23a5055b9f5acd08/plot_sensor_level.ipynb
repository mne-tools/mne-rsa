{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Sensor-level RSA using a searchlight\n\nThis example demonstrates how to perform representational similarity analysis (RSA) on\nEEG data, using a searchlight approach.\n\nIn the searchlight approach, representational similarity is computed between the model\nand searchlight \"patches\". A patch is defined by a seed point (e.g. sensor Pz) and\neverything within the given radius (e.g. all sensors within 4 cm. of Pz). Patches are\ncreated for all possible seed points (e.g. all sensors), so you can think of it as a\n\"searchlight\" that moves from seed point to seed point and everything that is in the\nspotlight is used in the computation.\n\nThe radius of a searchlight can be defined in space, in time, or both. In this example,\nour searchlight will have a spatial radius of 4.5 cm. and a temporal radius of 50 ms.\n\n..warning::\n    A searchlight across MEG sensors does not make a lot of sense, as the magnetic field\n    pattern does not lend itself well to circular searchlight patches.\n\nThe dataset will be the kiloword dataset [1]_: approximately 1,000 words were presented\nto 75 participants in a go/no-go lexical decision task while event-related potentials\n(ERPs) were recorded.\n\n.. [1] Dufau, S., Grainger, J., Midgley, KJ., Holcomb, PJ (2015). A thousand words are\n       worth a picture: Snapshots of printed-word processing in an event-related\n       potential megastudy. Psychological science.\n\n| Authors:\n| Marijn van Vliet <marijn.vanvliet@aalto.fi>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# sphinx_gallery_thumbnail_number=2\n\n# Import required packages\nimport mne\nimport mne_rsa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MNE-Python contains a built-in data loader for the kiloword dataset. We use it here to\nread it as 960 epochs. Each epoch represents the brain response to a single word,\naveraged across all the participants. For this example, we speed up the computation,\nat a cost of temporal precision, by downsampling the data from the original 250 Hz. to\n100 Hz.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_path = mne.datasets.kiloword.data_path(verbose=True)\nepochs = mne.read_epochs(data_path / \"kword_metadata-epo.fif\")\nepochs = epochs.resample(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The kiloword dataset was erroneously stored with sensor locations given in centimeters\ninstead of meters. We will fix it now. For your own data, the sensor locations are\nlikely properly stored in meters, so you can skip this step.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for ch in epochs.info[\"chs\"]:\n    ch[\"loc\"] /= 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The ``epochs`` object contains a ``.metadata`` field that contains information about\nthe 960 words that were used in the experiment. Let's have a look at the metadata for\n10 random words:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "epochs.metadata.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's pick something obvious for this example and build a dissimilarity matrix (RDM)\nbased on the number of letters in each word.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rdm_vis = mne_rsa.compute_rdm(epochs.metadata[[\"NumberOfLetters\"]], metric=\"euclidean\")\nmne_rsa.plot_rdms(rdm_vis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The above RDM will serve as our \"model\" RDM. In this example RSA analysis, we are\ngoing to compare the model RDM against RDMs created from the EEG data. The EEG RDMs\nwill be created using a \"searchlight\" pattern. We are using squared Euclidean distance\nfor our RDM metric, since we only have a few data points in each searchlight patch.\nFeel free to play around with other metrics.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rsa_result = mne_rsa.rsa_epochs(\n    epochs,  # The EEG data\n    rdm_vis,  # The model RDM\n    epochs_rdm_metric=\"sqeuclidean\",  # Metric to compute the EEG RDMs\n    rsa_metric=\"kendall-tau-a\",  # Metric to compare model and EEG RDMs\n    spatial_radius=0.05,  # Spatial radius of the searchlight patch in meters.\n    temporal_radius=0.05,  # Temporal radius of the searchlight path in seconds.\n    tmin=0.15,\n    tmax=0.25,  # To save time, only analyze this time interval\n    n_jobs=1,  # Only use one CPU core. Increase this for more speed.\n    n_folds=None,  # Don't use any cross-validation\n    verbose=False,\n)  # Set to True to display a progress bar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The result is packed inside an MNE-Python :class:`mne.Evoked` object. This object\ndefines many plotting functions, for example :meth:`mne.Evoked.plot_topomap` to look\nat the spatial distribution of the RSA values. By default, the signal is assumed to\nrepresent micro-Volts, so we need to explicitly inform the plotting function we are\nplotting RSA values and tweak the range of the colormap.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rsa_result.plot_topomap(\n    rsa_result.times,\n    units=dict(eeg=\"kendall-tau-a\"),\n    scalings=dict(eeg=1),\n    cbar_fmt=\"%.4f\",\n    vlim=(0, None),\n    nrows=2,\n    sphere=1,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unsurprisingly, we get the highest correspondence between number of letters and EEG\nsignal in areas in the [visual word form area](https://en.wikipedia.org/wiki/Visual_word_form_area).\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}