{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Source-level RSA using a searchlight on surface data\n\nThis example demonstrates how to perform representational similarity analysis (RSA) on\nsource localized MEG data, using a searchlight approach.\n\nIn the searchlight approach, representational similarity is computed between the model\nand searchlight \"patches\". A patch is defined by a seed vertex on the cortex and all\nvertices within a given radius. By default, patches are created using each vertex as a\nseed point, so you can think of it as a \"searchlight\" that scans along the cortex.\n\nThe radius of a searchlight can be defined in space, in time, or both. In this example,\nour searchlight will have a spatial radius of 2 cm. and a temporal radius of 20 ms.\n\nThe dataset will be the MNE-sample dataset: a collection of 288 epochs in which the\nparticipant was presented with an auditory beep or visual stimulus to either the left or\nright ear or visual field.\n\n| Authors:\n| Marijn van Vliet <marijn.vanvliet@aalto.fi>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# sphinx_gallery_thumbnail_number=2\n\nimport mne\nimport mne_rsa\n\n# Import required packages\nfrom matplotlib import pyplot as plt\n\nmne.set_log_level(False)  # Be less verbose\nmne.viz.set_3d_backend(\"pyvista\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll be using the data from the MNE-sample set. To speed up computations in this\nexample, we're going to use one of the sparse source spaces from the testing set.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sample_root = mne.datasets.sample.data_path(verbose=True)\ntesting_root = mne.datasets.testing.data_path(verbose=True)\nsample_path = sample_root / \"MEG\" / \"sample\"\ntesting_path = testing_root / \"MEG\" / \"sample\"\nsubjects_dir = sample_root / \"subjects\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating epochs from the continuous (raw) data. We downsample to 100 Hz to speed up\nthe RSA computations later on.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raw = mne.io.read_raw_fif(sample_path / \"sample_audvis_filt-0-40_raw.fif\")\nevents = mne.read_events(sample_path / \"sample_audvis_filt-0-40_raw-eve.fif\")\nevent_id = {\"audio/left\": 1, \"audio/right\": 2, \"visual/left\": 3, \"visual/right\": 4}\nepochs = mne.Epochs(raw, events, event_id, preload=True)\nepochs.resample(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It's important that the model RDM and the epochs are in the same order, so that each\nrow in the model RDM will correspond to an epoch. The model RDM will be easier to\ninterpret visually if the data is ordered such that all epochs belonging to the same\nexperimental condition are right next to each-other, so patterns jump out. This can be\nachieved by first splitting the epochs by experimental condition and then\nconcatenating them together again.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "epoch_splits = [\n    epochs[cl] for cl in [\"audio/left\", \"audio/right\", \"visual/left\", \"visual/right\"]\n]\nepochs = mne.concatenate_epochs(epoch_splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that the epochs are in the proper order, we can create a RDM based on the\nexperimental conditions. This type of RDM is referred to as a \"sensitivity RDM\". Let's\ncreate a sensitivity RDM that will pick up the left auditory response when RSA-ed\nagainst the MEG data. Since we want to capture areas where left beeps generate a large\nsignal, we specify that left beeps should be similar to other left beeps. Since we do\nnot want areas where visual stimuli generate a large signal, we specify that beeps\nmust be different from visual stimuli. Furthermore, since in areas where visual\nstimuli generate only a small signal, random noise will dominate, we also specify that\nvisual stimuli are different from other visual stimuli. Finally left and right\nauditory beeps will be somewhat similar.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def sensitivity_metric(event_id_1, event_id_2):\n    \"\"\"Determine similarity between two epochs, given their event ids.\"\"\"\n    if event_id_1 == 1 and event_id_2 == 1:\n        return 0  # Completely similar\n    if event_id_1 == 2 and event_id_2 == 2:\n        return 0.5  # Somewhat similar\n    elif event_id_1 == 1 and event_id_2 == 2:\n        return 0.5  # Somewhat similar\n    elif event_id_1 == 2 and event_id_1 == 1:\n        return 0.5  # Somewhat similar\n    else:\n        return 1  # Not similar at all\n\n\nmodel_rdm = mne_rsa.compute_rdm(epochs.events[:, 2], metric=sensitivity_metric)\nmne_rsa.plot_rdms(model_rdm, title=\"Model RDM\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This example is going to be on source-level, so let's load the inverse operator and\napply it to obtain a cortical surface source estimate for each epoch. To speed up the\ncomputation, we going to load an inverse operator from the testing dataset that was\ncreated using a sparse source space with not too many vertices.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv = mne.minimum_norm.read_inverse_operator(\n    testing_path / \"sample_audvis_trunc-meg-eeg-oct-4-meg-inv.fif\"\n)\nepochs_stc = mne.minimum_norm.apply_inverse_epochs(epochs, inv, lambda2=0.1111)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Performing the RSA. This will take some time. Consider increasing ``n_jobs`` to\nparallelize the computation across multiple CPUs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rsa_vals = mne_rsa.rsa_stcs(\n    epochs_stc,  # The source localized epochs\n    model_rdm,  # The model RDM we constructed above\n    src=inv[\"src\"],  # The inverse operator has our source space\n    stc_rdm_metric=\"correlation\",  # Metric to compute the MEG RDMs\n    rsa_metric=\"kendall-tau-a\",  # Metric to compare model and EEG RDMs\n    spatial_radius=0.02,  # Spatial radius of the searchlight patch\n    temporal_radius=0.02,  # Temporal radius of the searchlight path\n    tmin=0,\n    tmax=0.3,  # To save time, only analyze this time interval\n    n_jobs=1,  # Only use one CPU core. Increase this for more speed.\n    verbose=True,\n)  # Set to True to display a progress bar\n\n# Find the searchlight patch with highest RSA score\npeak_vertex, peak_time = rsa_vals.get_peak(vert_as_index=True)\n\n# Plot the result at the timepoint where the maximum RSA value occurs.\nrsa_vals.plot(\"sample\", subjects_dir=subjects_dir, initial_time=peak_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the RSA timecourse at the peak vertex\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure()\nplt.plot(rsa_vals.times, rsa_vals.data[peak_vertex])\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Kendall-Tau (alpha)\")\nplt.title(f\"RSA values at vert {peak_vertex}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}