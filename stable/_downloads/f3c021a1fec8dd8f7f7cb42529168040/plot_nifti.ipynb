{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Source-level RSA using a searchlight on fMRI data\n\nThis example demonstrates how to perform representational similarity analysis (RSA) on\nvolumetric fMRI data, using a searchlight approach.\n\nIn the searchlight approach, representational similarity is computed between the model\nand searchlight \"patches\". A patch is defined by a seed voxel and all voxels within a\ngiven radius. By default, patches are created using each voxel as a seed point, so you\ncan think of it as a \"searchlight\" that scans through the brain. In this example, our\nsearchlight will have a spatial radius of 1 cm.\n\nThe dataset will be the Haxby et al. 2001 dataset: a collection of 1452 scans during\nwhich the participant was presented with a stimulus image belonging to any of 8\ndifferent classes: scissors, face, cat, shoe, house, scrambledpix, bottle, chair.\n\n| Authors:\n| Marijn van Vliet <marijn.vanvliet@aalto.fi>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# sphinx_gallery_thumbnail_number=2\n\n# Import required packages\nimport mne_rsa\nimport nibabel as nib\nimport pandas as pd\nimport tarfile\nimport urllib.request\nfrom nilearn.plotting import plot_glass_brain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll be using the data from the Haxby et al. 2001 set, which can be found at:\nhttp://data.pymvpa.org/datasets/haxby2001\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Download and extract data\nfname, _ = urllib.request.urlretrieve(\n    \"http://data.pymvpa.org/datasets/haxby2001/subj1-2010.01.14.tar.gz\"\n)\ntar = tarfile.open(fname, \"r:gz\")\ntar.extractall()\ntar.close()\n\n# Load fMRI BOLD data\nbold = nib.load(\"subj1/bold.nii.gz\")\n\n# This is a mask that the authors provide. It is a GLM contrast based localizer map that\n# extracts an ROI in the \"ventral temporal\" region.\nmask = nib.load(\"subj1/mask4_vt.nii.gz\")\n\n# This is the metadata of the experiment. What stimulus was shown when etc.\nmeta = pd.read_csv(\"subj1/labels.txt\", sep=\" \")\nmeta[\"labels\"] = meta[\"labels\"].astype(\"category\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Drop \"rest\" class and sort images by class. We must ensure that all times, the\nmetadata and the bold images are in sync. Hence, we first perform the operations on\nthe ``meta`` pandas DataFrame. Then, we can use the DataFrame's index to repeat the\noperations on the BOLD data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "meta = meta[meta[\"labels\"] != \"rest\"].sort_values(\"labels\")\nbold = nib.Nifti1Image(bold.get_fdata()[..., meta.index], bold.affine, bold.header)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We're going to hunt for areas in the brain where the signal differentiates nicely\nbetween the various object categories. We encode this objective in our \"model\" RDM: a\nRDM where stimuli belonging to the same object category have a dissimilarity of 0 and\nstimuli belonging to different categories have a dissimilarity of 1.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_rdm = mne_rsa.compute_rdm(meta[\"labels\"], metric=lambda a, b: 0 if a == b else 1)\nmne_rsa.plot_rdms(model_rdm, \"Model RDM\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Performing the RSA. This will take some time. Consider increasing ``n_jobs`` to\nparallelize the computation across multiple CPUs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rsa_vals = mne_rsa.rsa_nifti(\n    bold,  # The BOLD data\n    model_rdm,  # The model RDM we constructed above\n    image_rdm_metric=\"correlation\",  # Metric to compute the BOLD RDMs\n    rsa_metric=\"kendall-tau-a\",  # Metric to compare model and BOLD RDMs\n    spatial_radius=0.01,  # Spatial radius of the searchlight patch\n    roi_mask=mask,  # Restrict analysis to the VT ROI\n    n_jobs=1,  # Only use one CPU core.\n    verbose=False,\n)  # Set to True to display a progress bar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the result using nilearn.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_glass_brain(rsa_vals)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}