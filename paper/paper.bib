@article{Diedrichsen2017,
  title = {Representational Models: {{A}} Common Framework for Understanding Encoding, Pattern-Component, and Representational-Similarity Analysis},
  shorttitle = {Representational Models},
  author = {Diedrichsen, J{\"o}rn and Kriegeskorte, Nikolaus},
  year = {2017},
  month = apr,
  journal = {PLOS Computational Biology},
  volume = {13},
  number = {4},
  pages = {e1005508},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1005508},
  urldate = {2019-07-23},
  abstract = {Representational models specify how activity patterns in populations of neurons (or, more generally, in multivariate brain-activity measurements) relate to sensory stimuli, motor responses, or cognitive processes. In an experimental context, representational models can be defined as hypotheses about the distribution of activity profiles across experimental conditions. Currently, three different methods are being used to test such hypotheses: encoding analysis, pattern component modeling (PCM), and representational similarity analysis (RSA). Here we develop a common mathematical framework for understanding the relationship of these three methods, which share one core commonality: all three evaluate the second moment of the distribution of activity profiles, which determines the representational geometry, and thus how well any feature can be decoded from population activity. Using simulated data for three different experimental designs, we compare the power of the methods to adjudicate between competing representational models. PCM implements a likelihood-ratio test and therefore provides the most powerful test if its assumptions hold. However, the other two approaches---when conducted appropriately---can perform similarly. In encoding analysis, the linear model needs to be appropriately regularized, which effectively imposes a prior on the activity profiles. With such a prior, an encoding model specifies a well-defined distribution of activity profiles. In RSA, the unequal variances and statistical dependencies of the dissimilarity estimates need to be taken into account to reach near-optimal power in inference. The three methods render different aspects of the information explicit (e.g. single-response tuning in encoding analysis and population-response representational dissimilarity in RSA) and have specific advantages in terms of computational demands, ease of use, and extensibility. The three methods are properly construed as complementary components of a single data-analytical toolkit for understanding neural representations on the basis of multivariate brain-activity data.},
  langid = {english},
  keywords = {Approximation methods,Functional magnetic resonance imaging,Musculoskeletal system,Neurons,Probability distribution,Signal to noise ratio,Simulation and modeling,Statistical noise},
  file = {/home/vanvlm1/Zotero/storage/RWJPKW2K/Diedrichsen and Kriegeskorte - 2017 - Representational models A common framework for un.pdf;/home/vanvlm1/Zotero/storage/CRWJL566/article.html}
}

@article{Guggenmos2018,
  title = {Multivariate Pattern Analysis for {{MEG}}: {{A}} Comparison of Dissimilarity Measures},
  shorttitle = {Multivariate Pattern Analysis for {{MEG}}},
  author = {Guggenmos, Matthias and Sterzer, Philipp and Cichy, Radoslaw Martin},
  year = {2018},
  month = jun,
  journal = {NeuroImage},
  volume = {173},
  pages = {434--447},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2018.02.044},
  urldate = {2019-06-25},
  abstract = {Multivariate pattern analysis (MVPA) methods such as decoding and representational similarity analysis (RSA) are growing rapidly in popularity for the analysis of magnetoencephalography (MEG) data. However, little is known about the relative performance and characteristics of the specific dissimilarity measures used to describe differences between evoked activation patterns. Here we used a multisession MEG data set to qualitatively characterize a range of dissimilarity measures and to quantitatively compare them with respect to decoding accuracy (for decoding) and between-session reliability of representational dissimilarity matrices (for RSA). We tested dissimilarity measures from a range of classifiers (Linear Discriminant Analysis -- LDA, Support Vector Machine -- SVM, Weighted Robust Distance -- WeiRD, Gaussian Na{\"i}ve Bayes -- GNB) and distances (Euclidean distance, Pearson correlation). In addition, we evaluated three key processing choices: 1) preprocessing (noise normalisation, removal of the pattern mean), 2) weighting decoding accuracies by decision values, and 3) computing distances in three different partitioning schemes (non-cross-validated, cross-validated, within-class-corrected). Four main conclusions emerged from our results. First, appropriate multivariate noise normalization substantially improved decoding accuracies and the reliability of dissimilarity measures. Second, LDA, SVM and WeiRD yielded high peak decoding accuracies and nearly identical time courses. Third, while using decoding accuracies for RSA was markedly less reliable than continuous distances, this disadvantage was ameliorated by decision-value-weighting of decoding accuracies. Fourth, the cross-validated Euclidean distance provided unbiased distance estimates and highly replicable representational dissimilarity matrices. Overall, we strongly advise the use of multivariate noise normalisation as a general preprocessing step, recommend LDA, SVM and WeiRD as classifiers for decoding and highlight the cross-validated Euclidean distance as a reliable and unbiased default choice for RSA.},
  keywords = {Cross-validation,Decoding,EEG,Machine learning,MEG,Multi-voxel pattern analysis,Noise normalisation,Representational similarity analysis},
  file = {/m/nbe/work/vanvlm1/papers/Guggenmos et al. - 2018 - Multivariate pattern analysis for MEG A compariso.pdf;/home/vanvlm1/Zotero/storage/T6PGLTUL/S1053811918301411.html}
}

@article{Kaniuth2022,
  title = {Feature-Reweighted Representational Similarity Analysis: {{A}} Method for Improving the Fit between Computational Models, Brains, and Behavior},
  shorttitle = {Feature-Reweighted Representational Similarity Analysis},
  author = {Kaniuth, Philipp and Hebart, Martin N.},
  year = {2022},
  month = aug,
  journal = {NeuroImage},
  volume = {257},
  pages = {119294},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2022.119294},
  urldate = {2022-07-11},
  abstract = {Representational Similarity Analysis (RSA) has emerged as a popular method for relating representational spaces from human brain activity, behavioral data, and computational models. RSA is based on the comparison of representational (dis-)similarity matrices (RDMs or RSMs), which characterize the pairwise (dis-)similarities of all conditions across all features (e.g. fMRI voxels or units of a model). However, classical RSA treats each feature as equally important. This `equal weights' assumption contrasts with the flexibility of multivariate decoding, which reweights individual features for predicting a target variable. As a consequence, classical RSA may lead researchers to underestimate the correspondence between a model and a brain region and, in case of model comparison, may lead them to select an inferior model. The aim of this work is twofold: First, we sought to broadly test feature-reweighted RSA (FR-RSA) applied to computational models and reveal the extent to which reweighting model features improves RSM correspondence and affects model selection. Previous work suggested that reweighting can improve model selection in RSA but it has remained unclear to what extent these results generalize across datasets and data modalities. To draw more general conclusions, we utilized a range of publicly available datasets and three popular deep neural networks (DNNs). Second, we propose voxel-reweighted RSA, a novel use case of FR-RSA that reweights fMRI voxels, mirroring the rationale of multivariate decoding of optimally combining voxel activity patterns. We found that reweighting individual model units markedly improved the fit between model RSMs and target RSMs derived from several fMRI and behavioral datasets and affected model selection, highlighting the importance of considering FR-RSA. For voxel-reweighted RSA, improvements in RSM correspondence were even more pronounced, demonstrating the utility of this novel approach. We additionally show that classical noise ceilings can be exceeded when FR-RSA is applied and propose an updated approach for their computation. Taken together, our results broadly validate the use of FR-RSA for improving the fit between computational models, brain, and behavioral data, allowing us to better adjudicate between competing computational models. Further, our results suggest that FR-RSA applied to brain measurement channels could become an important new method to assess the correspondence between representational spaces.},
  langid = {english},
  keywords = {Behavior,Deep neural networks,Functional MRI,MEG,Multivariate pattern analysis,Noise ceilings,Representational similarity analysis},
  file = {/m/nbe/work/vanvlm1/papers/Kaniuth_Hebart_2022_Feature-reweighted representational similarity analysis.pdf;/home/vanvlm1/Zotero/storage/FF45NFTK/S105381192200413X.html}
}

@article{Kriegeskorte2008,
  title = {Representational Similarity Analysis - Connecting the Branches of Systems Neuroscience.},
  author = {Kriegeskorte, Nikolaus and Mur, Marieke and Bandettini, Peter A.},
  year = {2008},
  journal = {Frontiers in systems neuroscience},
  volume = {2},
  number = {November},
  pages = {4},
  issn = {1662-5137},
  doi = {10.3389/neuro.06.004.2008},
  abstract = {A FUNDAMENTAL CHALLENGE FOR SYSTEMS NEUROSCIENCE IS TO QUANTITATIVELY RELATE ITS THREE MAJOR BRANCHES OF RESEARCH: brain-activity measurement, behavioral measurement, and computational modeling. Using measured brain-activity patterns to evaluate computational network models is complicated by the need to define the correspondency between the units of the model and the channels of the brain-activity data, e.g., single-cell recordings or voxels from functional magnetic resonance imaging (fMRI). Similar correspondency problems complicate relating activity patterns between different modalities of brain-activity measurement (e.g., fMRI and invasive or scalp electrophysiology), and between subjects and species. In order to bridge these divides, we suggest abstracting from the activity patterns themselves and computing representational dissimilarity matrices (RDMs), which characterize the information carried by a given representation in a brain or model. Building on a rich psychological and mathematical literature on similarity analysis, we propose a new experimental and data-analytical framework called representational similarity analysis (RSA), in which multi-channel measures of neural activity are quantitatively related to each other and to computational theory and behavior by comparing RDMs. We demonstrate RSA by relating representations of visual objects as measured with fMRI in early visual cortex and the fusiform face area to computational models spanning a wide range of complexities. The RDMs are simultaneously related via second-level application of multidimensional scaling and tested using randomization and bootstrap techniques. We discuss the broad potential of RSA, including novel approaches to experimental design, and argue that these ideas, which have deep roots in psychology and neuroscience, will allow the integrated quantitative analysis of data from all three branches, thus contributing to a more unified systems neuroscience.},
  isbn = {1662-5137 (Electronic) 1662-5137 (Linking)},
  pmid = {19104670},
  keywords = {computational modeling,electrophysiology,fmri,population code,representation,similarity},
  file = {/m/nbe/work/vanvlm1/papers/Kriegeskorte et al. - 2008 - Representational similarity analysis - connecting .pdf}
}

@article{Nili2014,
  title = {A {{Toolbox}} for {{Representational Similarity Analysis}}},
  author = {Nili, Hamed and Wingfield, Cai and Walther, Alexander and Su, Li and {Marslen-Wilson}, William and Kriegeskorte, Nikolaus},
  year = {2014},
  month = apr,
  journal = {PLOS Computational Biology},
  volume = {10},
  number = {4},
  pages = {e1003553},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1003553},
  urldate = {2018-08-24},
  abstract = {Neuronal population codes are increasingly being investigated with multivariate pattern-information analyses. A key challenge is to use measured brain-activity patterns to test computational models of brain information processing. One approach to this problem is representational similarity analysis (RSA), which characterizes a representation in a brain or computational model by the distance matrix of the response patterns elicited by a set of stimuli. The representational distance matrix encapsulates what distinctions between stimuli are emphasized and what distinctions are de-emphasized in the representation. A model is tested by comparing the representational distance matrix it predicts to that of a measured brain region. RSA also enables us to compare representations between stages of processing within a given brain or model, between brain and behavioral data, and between individuals and species. Here, we introduce a Matlab toolbox for RSA. The toolbox supports an analysis approach that is simultaneously data- and hypothesis-driven. It is designed to help integrate a wide range of computational models into the analysis of multichannel brain-activity measurements as provided by modern functional imaging and neuronal recording techniques. Tools for visualization and inference enable the user to relate sets of models to sets of brain regions and to statistically test and compare the models using nonparametric inference methods. The toolbox supports searchlight-based RSA, to continuously map a measured brain volume in search of a neuronal population code with a specific geometry. Finally, we introduce the linear-discriminant t value as a measure of representational discriminability that bridges the gap between linear decoding analyses and RSA. In order to demonstrate the capabilities of the toolbox, we apply it to both simulated and real fMRI data. The key functions are equally applicable to other modalities of brain-activity measurement. The toolbox is freely available to the community under an open-source license agreement (http://www.mrc-cbu.cam.ac.uk/methods-and-resources/toolboxes/license/).},
  langid = {english},
  keywords = {Distance measurement,Face,Functional magnetic resonance imaging,Gaussian noise,Information processing,Simulation and modeling,Software tools,Statistical inference},
  file = {/u/45/vanvlm1/unix/Downloads/journal.pcbi.1003553.PDF;/home/vanvlm1/Zotero/storage/WTJ8N8JW/article.html}
}
@article{Hulten2021,
  title = {The Neural Representation of Abstract Words May Arise through Grounding Word Meaning in Language Itself},
  author = {Hult{\'e}n, Annika and {van Vliet}, Marijn and Kivisaari, Sasa and Lammi, Lotta and {Lindh-Knuutila}, Tiina and Faisal, Ali and Salmelin, Riitta},
  year = {2021},
  journal = {Human Brain Mapping},
  volume = {42},
  number = {15},
  pages = {4973--4984},
  issn = {1097-0193},
  doi = {10.1002/hbm.25593},
  urldate = {2021-09-28},
  abstract = {In order to describe how humans represent meaning in the brain, one must be able to account for not just concrete words but, critically, also abstract words, which lack a physical referent. Hebbian formalism and optimization are basic principles of brain function, and they provide an appealing approach for modeling word meanings based on word co-occurrences. We provide proof of concept that a statistical model of the semantic space can account for neural representations of both concrete and abstract words, using MEG. Here, we built a statistical model using word embeddings extracted from a text corpus. This statistical model was used to train a machine learning algorithm to successfully decode the MEG signals evoked by written words. In the model, word abstractness emerged from the statistical regularities of the language environment. Representational similarity analysis further showed that this salient property of the model co-varies, at 280--420 ms after visual word presentation, with activity in regions that have been previously linked with processing of abstract words, namely the left-hemisphere frontal, anterior temporal and superior parietal cortex. In light of these results, we propose that the neural encoding of word meanings can arise through statistical regularities, that is, through grounding in language itself.},
  copyright = {Creative Commons Attribution 4.0 International License (CC-BY)},
  langid = {english},
  keywords = {abstract concepts,concrete words,decoding,machine learning,MEG,RSA,semantics,word processing},
  file = {/m/nbe/work/vanvlm1/papers/Hultén et al_2021_The neural representation of abstract words may arise through grounding word.pdf;/home/vanvlm1/Zotero/storage/7KN6FXCL/hbm.html}
}
@article{Xu2024,
  title = {Neural Correlates of Retrospective Memory Confidence during Face--Name Associative Learning},
  author = {Xu, Weiyong and Li, Xueqiao and Parviainen, Tiina and Nokia, Miriam},
  year = {2024},
  month = may,
  journal = {Cerebral Cortex},
  volume = {34},
  number = {5},
  pages = {bhae194},
  issn = {1460-2199},
  doi = {10.1093/cercor/bhae194},
  urldate = {2025-06-13},
  abstract = {The ability to accurately assess one's own memory performance during learning is essential for adaptive behavior, but the brain mechanisms underlying this metamemory function are not well understood. We investigated the neural correlates of memory accuracy and retrospective memory confidence in a face--name associative learning task using magnetoencephalography in healthy young adults (n\,=\,32). We found that high retrospective confidence was associated with stronger occipital event-related fields during encoding and widespread event-related fields during retrieval compared to low confidence. On the other hand, memory accuracy was linked to medial temporal activities during both encoding and retrieval, but only in low-confidence trials. A decrease in oscillatory power at alpha/beta bands in the parietal regions during retrieval was associated with higher memory confidence. In addition, representational similarity analysis at the single-trial level revealed distributed but differentiable neural activities associated with memory accuracy and confidence during both encoding and retrieval. In summary, our study unveiled distinct neural activity patterns related to memory confidence and accuracy during associative learning and underscored the crucial role of parietal regions in metamemory.},
  file = {/home/vanvlm1/Zotero/storage/T576MNJX/Xu et al. - 2024 - Neural correlates of retrospective memory confidence during face–name associative learning.pdf;/home/vanvlm1/Zotero/storage/EPWD3ZB9/7668683.html}
}

@article{Messi2025,
  title = {Tracking Neural Correlates of Contextualized Meanings with Representational Similarity Analysis},
  author = {Messi, Aline-Priscillia and Pylkkanen, Liina},
  year = {2025},
  month = may,
  journal = {Journal of Neuroscience},
  volume = {45},
  number = {19},
  publisher = {Society for Neuroscience},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.0409-24.2025},
  urldate = {2025-06-13},
  abstract = {Although it is uncontroversial that word meanings shift depending on their context, our understanding of contextualized lexical meaning remains poor. How is a contextualized semantic space organized? In this MEG study (27 human participants, 16 women, 10 men, 1 nonbinary), we manipulated the semantic and syntactic contexts of wordforms to query the organization of this space. All wordforms were noun/verb ambiguous and varied in the semantic distance between their noun and verb uses: unambiguous stems, polysemes with distinct but related meanings, and homonyms with completely unrelated meanings. The senses of each stem were disambiguated by a unique discourse sentence and the items were placed in syntactic contexts of varying sizes. Univariate results characterized syntactic context as a bilateral and distributed effect. A multivariate representational similarity analysis correlated one-hot models of the categorical factors and contextualized embedding-based models with MEG activity. Of all models representing ambiguity, only a model differentiating between syntactic categories across contexts correlated with the brain. An All-Embeddings model, where each contextualized word had a distinct representation, explained distributed neural activity across the left hemisphere. Finally, a Syntactic Context model and Within-Context-Stem model were significant in left occipitoparietal regions. While the noun versus verb contrast affected neural signals robustly, we saw no evidence of the homonym--polyseme--unambiguous contrast, over and above the evidence for fully itemized representations. These findings suggest that in contexts devoid of ambiguity, the neural representation of a word is mainly shaped by its syntactic category and its contextually informed, unique semantic representation.},
  chapter = {Research Articles},
  copyright = {Copyright {\copyright} 2025 the authors. SfN exclusive license.},
  langid = {english},
  pmid = {40147935},
  keywords = {contextualized meaning,magnetoencephalography,representational similarity analysis,semantic ambiguity,semantic representation,syntactic category},
  file = {/m/nbe/work/vanvlm1/papers/Messi and Pylkkanen - 2025 - Tracking Neural Correlates of Contextualized Meanings with Representational Similarity Analysis.pdf}
}
@article{Ghazaryan2023,
  title = {Cortical Time-Course of Evidence Accumulation during Semantic Processing},
  author = {Ghazaryan, Gayane and {van Vliet}, Marijn and Lammi, Lotta and {Lindh-Knuutila}, Tiina and Kivisaari, Sasa and Hult{\'e}n, Annika and Salmelin, Riitta},
  year = {2023},
  month = dec,
  journal = {Communications Biology},
  volume = {6},
  number = {1},
  pages = {1--12},
  publisher = {Nature Publishing Group},
  issn = {2399-3642},
  doi = {10.1038/s42003-023-05611-6},
  urldate = {2024-05-21},
  abstract = {Our understanding of the surrounding world and communication with other people are tied to mental representations of concepts. In order for the brain to recognize an object, it must determine which concept to access based on information available from sensory inputs. In this study, we combine magnetoencephalography and machine learning to investigate how concepts are represented and accessed in the brain over time. Using brain responses from a silent picture naming task, we track the dynamics of visual and semantic information processing, and show that the brain gradually accumulates information on different levels before eventually reaching a plateau. The timing of this plateau point varies across individuals and feature models, indicating notable temporal variation in visual object recognition and semantic processing.},
  copyright = {2023 The Author(s)},
  langid = {english},
  keywords = {Language,Neural decoding},
  file = {/m/nbe/work/vanvlm1/papers/Ghazaryan et al_2023_Cortical time-course of evidence accumulation during semantic processing.pdf}
}
@article{Klimovich-Gray2021,
  title = {One Way or Another: Cortical Language Areas Flexibly Adapt Processing Strategies to Perceptual And Contextual Properties of Speech},
  shorttitle = {One {{Way}} or {{Another}}},
  author = {{Klimovich-Gray}, Anastasia and Barrena, Ander and Agirre, Eneko and Molinaro, Nicola},
  year = {2021},
  month = sep,
  journal = {Cerebral Cortex},
  volume = {31},
  number = {9},
  pages = {4092--4103},
  issn = {1047-3211},
  doi = {10.1093/cercor/bhab071},
  urldate = {2025-06-13},
  abstract = {Cortical circuits rely on the temporal regularities of speech to optimize signal parsing for sound-to-meaning mapping. Bottom-up speech analysis is accelerated by top--down predictions about upcoming words. In everyday communications, however, listeners are regularly presented with challenging input---fluctuations of speech rate or semantic content. In this study, we asked how reducing speech temporal regularity affects its processing---parsing, phonological analysis, and ability to generate context-based predictions. To ensure that spoken sentences were natural and approximated semantic constraints of spontaneous speech we built a neural network to select stimuli from large corpora. We analyzed brain activity recorded with magnetoencephalography during sentence listening using evoked responses, speech-to-brain synchronization and representational similarity analysis. For normal speech theta band (6.5--8~Hz) speech-to-brain synchronization was increased and the left fronto-temporal areas generated stronger contextual predictions. The reverse was true for temporally irregular speech---weaker theta synchronization and reduced top--down effects. Interestingly, delta-band (0.5 Hz) speech tracking was greater when contextual/semantic predictions were lower or if speech was temporally jittered. We conclude that speech temporal regularity is relevant for (theta) syllabic tracking and robust semantic predictions while the joint support of temporal and contextual predictability reduces word and phrase-level cortical tracking (delta).},
  file = {/home/vanvlm1/Zotero/storage/IQ64IVQT/Klimovich-Gray et al. - 2021 - One Way or Another Cortical Language Areas Flexibly Adapt Processing Strategies to Perceptual And C.pdf}
}
@article{Gramfort2013,
  title = {{{MEG}} and {{EEG}} Data Analysis with {{MNE-Python}}},
  author = {Gramfort, Alexandre and Luessi, Martin and Larson, Eric and Engemann, Denis A. and Strohmeier, Daniel and Brodbeck, Christian and Goj, Roman and Jas, Mainak and Brooks, Teon and Parkkonen, Lauri and H{\"a}m{\"a}l{\"a}inen, Matti S},
  year = {2013},
  journal = {Frontiers in Neuroscience},
  volume = {7},
  number = {December},
  pages = {1--13},
  issn = {1662-453X},
  doi = {10.3389/fnins.2013.00267},
  abstract = {Magnetoencephalography and electroencephalography (M/EEG) measure the weakelectromagnetic signals generated by neuronal activity in the brain. Using thesesignals to characterize and locate neural activation in the brain is achallenge that requires expertise in physics, signalprocessing, statistics, and numerical methods. As part of the MNE softwaresuite, MNE-Python is an open-sourcesoftware package that addresses this challenge by providingstate-of-the-art algorithms implemented in Python that cover multiple methods of data preprocessing, source localization, statistical analysis, and estimation offunctional connectivity between distributed brain regions.All algorithms and utility functions are implemented in a consistent manner with well-documented interfaces, enabling users to create M/EEG data analysispipelines by writing Python scripts.Moreover, MNE-Python is tightly integrated with the core Python libraries for scientificcomptutation (Numpy, Scipy) and visualization (matplotlib and Mayavi), as wellas the greater neuroimaging ecosystem in Python via the Nibabel package. The code is provided under the new BSD licenseallowing code reuse, even in commercial products. Although MNE-Python has onlybeen under heavy development for a couple of years, it has rapidly evolved withexpanded analysis capabilities and pedagogical tutorials because multiple labs have collaborated during code development to help share best practices.MNE-Python also gives easy access to preprocessed datasets,helping users to get started quickly and facilitating reproducibility ofmethods by other researchers. Full documentation, including dozens ofexamples, is available at http://martinos.org/mne.},
  keywords = {eeg,electroencephalography,electroencephalography (EEG),magnetoencephalography,magnetoencephalography (MEG),meg,neuroimaging,open-source,python,software},
  file = {S:\work\vanvlm1\papers\Gramfort et al. - 2013 - MEG and EEG data analysis with MNE-Python.pdf}
}
@article{Guggenmos2018,
  title = {Multivariate Pattern Analysis for {{MEG}}: {{A}} Comparison of Dissimilarity Measures},
  shorttitle = {Multivariate Pattern Analysis for {{MEG}}},
  author = {Guggenmos, Matthias and Sterzer, Philipp and Cichy, Radoslaw Martin},
  year = {2018},
  month = jun,
  journal = {NeuroImage},
  volume = {173},
  pages = {434--447},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2018.02.044},
  urldate = {2019-06-25},
  abstract = {Multivariate pattern analysis (MVPA) methods such as decoding and representational similarity analysis (RSA) are growing rapidly in popularity for the analysis of magnetoencephalography (MEG) data. However, little is known about the relative performance and characteristics of the specific dissimilarity measures used to describe differences between evoked activation patterns. Here we used a multisession MEG data set to qualitatively characterize a range of dissimilarity measures and to quantitatively compare them with respect to decoding accuracy (for decoding) and between-session reliability of representational dissimilarity matrices (for RSA). We tested dissimilarity measures from a range of classifiers (Linear Discriminant Analysis -- LDA, Support Vector Machine -- SVM, Weighted Robust Distance -- WeiRD, Gaussian Na{\"i}ve Bayes -- GNB) and distances (Euclidean distance, Pearson correlation). In addition, we evaluated three key processing choices: 1) preprocessing (noise normalisation, removal of the pattern mean), 2) weighting decoding accuracies by decision values, and 3) computing distances in three different partitioning schemes (non-cross-validated, cross-validated, within-class-corrected). Four main conclusions emerged from our results. First, appropriate multivariate noise normalization substantially improved decoding accuracies and the reliability of dissimilarity measures. Second, LDA, SVM and WeiRD yielded high peak decoding accuracies and nearly identical time courses. Third, while using decoding accuracies for RSA was markedly less reliable than continuous distances, this disadvantage was ameliorated by decision-value-weighting of decoding accuracies. Fourth, the cross-validated Euclidean distance provided unbiased distance estimates and highly replicable representational dissimilarity matrices. Overall, we strongly advise the use of multivariate noise normalisation as a general preprocessing step, recommend LDA, SVM and WeiRD as classifiers for decoding and highlight the cross-validated Euclidean distance as a reliable and unbiased default choice for RSA.},
  keywords = {Cross-validation,Decoding,EEG,Machine learning,MEG,Multi-voxel pattern analysis,Noise normalisation,Representational similarity analysis},
  file = {S\:\\work\\vanvlm1\\papers\\Guggenmos et al. - 2018 - Multivariate pattern analysis for MEG A compariso.pdf;C\:\\Users\\wmvan\\Zotero\\storage\\T6PGLTUL\\S1053811918301411.html}
}
@article{Hanke2009,
  title = {{{PyMVPA}}: A Python Toolbox for Multivariate Pattern Analysis of fMRI Data},
  shorttitle = {{{PyMVPA}}},
  author = {Hanke, Michael and Halchenko, Yaroslav O. and Sederberg, Per B. and Hanson, Stephen Jos{\'e} and Haxby, James V. and Pollmann, Stefan},
  year = {2009},
  month = mar,
  journal = {Neuroinformatics},
  volume = {7},
  number = {1},
  pages = {37--53},
  issn = {1559-0089},
  doi = {10.1007/s12021-008-9041-y},
  urldate = {2025-06-13},
  abstract = {Decoding patterns of neural activity onto cognitive states is one of the central goals of functional brain imaging. Standard univariate fMRI analysis methods, which correlate cognitive and perceptual function with the blood oxygenation-level dependent (BOLD) signal, have proven successful in identifying anatomical regions based on signal increases during cognitive and perceptual tasks. Recently, researchers have begun to explore new multivariate techniques that have proven to be more flexible, more reliable, and more sensitive than standard univariate analysis. Drawing on the field of statistical learning theory, these new classifier-based analysis techniques possess explanatory power that could provide new insights into the functional properties of the brain. However, unlike the wealth of software packages for univariate analyses, there are few packages that facilitate multivariate pattern classification analyses of fMRI data. Here we introduce a Python-based, cross-platform, and open-source software toolbox, called PyMVPA, for the application of classifier-based analysis techniques to fMRI datasets. PyMVPA makes use of Python's ability to access libraries written in a large variety of programming languages and computing environments to interface with the wealth of existing machine learning packages. We present the framework in this paper and provide illustrative examples on its usage, features, and programmability.},
  langid = {english},
  keywords = {Brain Mapping,Computational Neuroscience,Functional magnetic resonance imaging,Image analysis,Machine learning,Machine Learning,Multivariate Analysis,MVPA,Neuroimaging software,Python,Scripting,Statistical Software},
  file = {S:\work\vanvlm1\papers\Hanke et al. - 2009 - PyMVPA a Python Toolbox for Multivariate Pattern Analysis of fMRI Data.pdf}
}
