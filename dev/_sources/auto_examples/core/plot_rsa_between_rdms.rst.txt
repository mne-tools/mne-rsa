
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/core/plot_rsa_between_rdms.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_core_plot_rsa_between_rdms.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_core_plot_rsa_between_rdms.py:


Compute RSA between RDMs
------------------------

This example showcases the most basic version of RSA: computing the similarity between
two RDMs. Then we continue with computing RSA between many RDMs efficiently.

| Authors:
| Marijn van Vliet <marijn.vanvliet@aalto.fi>

.. GENERATED FROM PYTHON SOURCE LINES 14-23

.. code-block:: Python

    # sphinx_gallery_thumbnail_number=2

    import mne
    import mne_rsa

    # Import required packages
    import pandas as pd
    from matplotlib import pyplot as plt








.. GENERATED FROM PYTHON SOURCE LINES 24-28

MNE-Python contains a built-in data loader for the kiloword dataset, which is used
here as an example dataset. Since we only need the words shown during the experiment,
which are in the metadata, we can pass ``preload=False`` to prevent MNE-Python from
loading the EEG data, which is a nice speed gain.

.. GENERATED FROM PYTHON SOURCE LINES 28-35

.. code-block:: Python


    data_path = mne.datasets.kiloword.data_path(verbose=True)
    epochs = mne.read_epochs(data_path / "kword_metadata-epo.fif")

    # Show the metadata of 10 random epochs
    epochs.metadata.sample(10)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Reading /home/runner/mne_data/MNE-kiloword-data/kword_metadata-epo.fif ...
    Isotrak not found
        Found the data of interest:
            t =    -100.00 ...     920.00 ms
            0 CTF compensation matrices available
    Adding metadata with 8 columns
    960 matching events found
    No baseline correction applied
    0 projection items activated


.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>WORD</th>
          <th>Concreteness</th>
          <th>WordFrequency</th>
          <th>OrthographicDistance</th>
          <th>NumberOfLetters</th>
          <th>BigramFrequency</th>
          <th>ConsonantVowelProportion</th>
          <th>VisualComplexity</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>739</th>
          <td>mine</td>
          <td>4.75</td>
          <td>3.154424</td>
          <td>1.00</td>
          <td>4.0</td>
          <td>632.750000</td>
          <td>0.500000</td>
          <td>69.716505</td>
        </tr>
        <tr>
          <th>874</th>
          <td>picture</td>
          <td>5.55</td>
          <td>3.280123</td>
          <td>2.40</td>
          <td>7.0</td>
          <td>388.714286</td>
          <td>0.571429</td>
          <td>60.240495</td>
        </tr>
        <tr>
          <th>516</th>
          <td>diva</td>
          <td>5.00</td>
          <td>0.301030</td>
          <td>1.85</td>
          <td>4.0</td>
          <td>498.000000</td>
          <td>0.500000</td>
          <td>64.978277</td>
        </tr>
        <tr>
          <th>171</th>
          <td>embrace</td>
          <td>4.15</td>
          <td>2.103804</td>
          <td>2.65</td>
          <td>7.0</td>
          <td>279.142857</td>
          <td>0.571429</td>
          <td>74.097404</td>
        </tr>
        <tr>
          <th>574</th>
          <td>crust</td>
          <td>5.80</td>
          <td>2.096910</td>
          <td>1.75</td>
          <td>5.0</td>
          <td>458.000000</td>
          <td>0.800000</td>
          <td>56.886661</td>
        </tr>
        <tr>
          <th>46</th>
          <td>feud</td>
          <td>3.25</td>
          <td>1.322219</td>
          <td>1.75</td>
          <td>4.0</td>
          <td>144.250000</td>
          <td>0.500000</td>
          <td>69.320525</td>
        </tr>
        <tr>
          <th>152</th>
          <td>example</td>
          <td>3.80</td>
          <td>3.636187</td>
          <td>2.70</td>
          <td>7.0</td>
          <td>349.714286</td>
          <td>0.571429</td>
          <td>73.838087</td>
        </tr>
        <tr>
          <th>639</th>
          <td>shelter</td>
          <td>5.00</td>
          <td>2.555094</td>
          <td>1.90</td>
          <td>7.0</td>
          <td>761.714286</td>
          <td>0.714286</td>
          <td>61.154305</td>
        </tr>
        <tr>
          <th>123</th>
          <td>camera</td>
          <td>6.20</td>
          <td>2.635484</td>
          <td>2.10</td>
          <td>6.0</td>
          <td>941.166667</td>
          <td>0.500000</td>
          <td>71.909491</td>
        </tr>
        <tr>
          <th>620</th>
          <td>heresy</td>
          <td>3.15</td>
          <td>1.740363</td>
          <td>2.05</td>
          <td>6.0</td>
          <td>667.666667</td>
          <td>0.500000</td>
          <td>68.277252</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 36-37

Compute RDMs based on word length and visual complexity.

.. GENERATED FROM PYTHON SOURCE LINES 37-45

.. code-block:: Python


    metadata = epochs.metadata
    rdm1 = mne_rsa.compute_rdm(metadata.NumberOfLetters, metric="euclidean")
    rdm2 = mne_rsa.compute_rdm(metadata.VisualComplexity, metric="euclidean")

    # Plot the RDMs
    mne_rsa.plot_rdms([rdm1, rdm2], names=["Word length", "Vis. complexity"])




.. image-sg:: /auto_examples/core/images/sphx_glr_plot_rsa_between_rdms_001.png
   :alt: Word length, Vis. complexity
   :srcset: /auto_examples/core/images/sphx_glr_plot_rsa_between_rdms_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <Figure size 400x200 with 3 Axes>



.. GENERATED FROM PYTHON SOURCE LINES 46-47

Perform RSA between the two RDMs using Spearman correlation

.. GENERATED FROM PYTHON SOURCE LINES 47-51

.. code-block:: Python


    rsa_result = mne_rsa.rsa(rdm1, rdm2, metric="spearman")
    print("RSA score:", rsa_result)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    RSA score: 0.026439883289118636




.. GENERATED FROM PYTHON SOURCE LINES 52-54

We can compute RSA between multiple RDMs by passing lists to the :func:`mne_rsa.rsa`
function.

.. GENERATED FROM PYTHON SOURCE LINES 54-70

.. code-block:: Python


    # Create RDMs for each stimulus property
    columns = metadata.columns[1:]  # Skip the first column: WORD
    rdms = [mne_rsa.compute_rdm(metadata[col], metric="euclidean") for col in columns]

    # Plot the RDMs
    fig = mne_rsa.plot_rdms(rdms, names=columns, n_rows=2)
    fig.set_size_inches(12, 4)

    # Compute RSA between the first two RDMs (Concreteness and WordFrequency) and the
    # others.
    rsa_results = mne_rsa.rsa(rdms[:2], rdms[2:], metric="spearman")

    # Pack the result into a Pandas DataFrame for easy viewing
    print(pd.DataFrame(rsa_results, index=columns[:2], columns=columns[2:]))




.. image-sg:: /auto_examples/core/images/sphx_glr_plot_rsa_between_rdms_002.png
   :alt: Concreteness, WordFrequency, OrthographicDistance, NumberOfLetters, BigramFrequency, ConsonantVowelProportion, VisualComplexity
   :srcset: /auto_examples/core/images/sphx_glr_plot_rsa_between_rdms_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

                   OrthographicDistance  ...  VisualComplexity
    Concreteness               0.031064  ...          0.004263
    WordFrequency              0.058385  ...         -0.009620

    [2 rows x 5 columns]




.. GENERATED FROM PYTHON SOURCE LINES 71-90

What if we have many RDMs? The :func:`mne_rsa.rsa` function is optimized for the case
where the first parameter (the "data" RDMs) is a large list of RDMs and the second
parameter (the "model" RDMs) is a smaller list. To save memory, you can also pass
generators instead of lists.

Let's create a generator that creates RDMs for each time-point in the EEG data and
compute the RSA between those RDMs and all the "model" RDMs we computed above. This is
a basic example of using a "searchlight" and in other examples, you can learn how to
use the :class:`mne_rsa.searchlight` generator to build more advanced searchlights.
However, since this is such a simple case, it is educational to construct the
generator manually.

The RSA computation will take some time. Therefore, we pass a few extra parameters to
:func:`mne_rsa.rsa` to enable some improvements. First, the ``verbose=True`` enables a
progress bar. However, since we are using a generator, the progress bar cannot
automatically infer how many RDMs there will be. Hence, we provide this information
explicitly using the ``n_data_rdms`` parameter. Finally, depending on how many CPUs
you have on your system, consider increasing the ``n_jobs`` parameter to parallelize
the computation over multiple CPUs.

.. GENERATED FROM PYTHON SOURCE LINES 90-117

.. code-block:: Python


    epochs.resample(100)  # Downsample to speed things up for this example
    eeg_data = epochs.get_data()
    n_trials, n_sensors, n_times = eeg_data.shape


    def generate_eeg_rdms():
        """Generate RDMs for each time sample."""
        for i in range(n_times):
            yield mne_rsa.compute_rdm(eeg_data[:, :, i], metric="correlation")


    rsa_results = mne_rsa.rsa(
        generate_eeg_rdms(),
        rdms,
        metric="spearman",
        verbose=True,
        n_data_rdms=n_times,
        n_jobs=1,  # Use this to specify the number of CPU cores to use.
    )

    # Plot the RSA values over time using standard matplotlib commands
    plt.figure(figsize=(8, 4))
    plt.plot(epochs.times, rsa_results)
    plt.xlabel("time (s)")
    plt.ylabel("RSA value")
    plt.legend(columns)



.. image-sg:: /auto_examples/core/images/sphx_glr_plot_rsa_between_rdms_003.png
   :alt: plot rsa between rdms
   :srcset: /auto_examples/core/images/sphx_glr_plot_rsa_between_rdms_003.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/102 [00:00<?, ?RDM/s]      1%|          | 1/102 [00:00<00:36,  2.75RDM/s]      3%|▎         | 3/102 [00:00<00:15,  6.52RDM/s]      5%|▍         | 5/102 [00:00<00:11,  8.65RDM/s]      7%|▋         | 7/102 [00:00<00:09,  9.90RDM/s]      9%|▉         | 9/102 [00:01<00:08, 10.73RDM/s]     11%|█         | 11/102 [00:01<00:08, 11.29RDM/s]     13%|█▎        | 13/102 [00:01<00:07, 11.68RDM/s]     15%|█▍        | 15/102 [00:01<00:07, 11.93RDM/s]     17%|█▋        | 17/102 [00:01<00:07, 12.11RDM/s]     19%|█▊        | 19/102 [00:01<00:06, 12.23RDM/s]     21%|██        | 21/102 [00:01<00:06, 12.32RDM/s]     23%|██▎       | 23/102 [00:02<00:06, 12.40RDM/s]     25%|██▍       | 25/102 [00:02<00:06, 12.46RDM/s]     26%|██▋       | 27/102 [00:02<00:06, 12.48RDM/s]     28%|██▊       | 29/102 [00:02<00:05, 12.51RDM/s]     30%|███       | 31/102 [00:02<00:05, 12.53RDM/s]     32%|███▏      | 33/102 [00:02<00:05, 12.51RDM/s]     34%|███▍      | 35/102 [00:03<00:05, 12.54RDM/s]     36%|███▋      | 37/102 [00:03<00:05, 12.58RDM/s]     38%|███▊      | 39/102 [00:03<00:05, 12.58RDM/s]     40%|████      | 41/102 [00:03<00:04, 12.59RDM/s]     42%|████▏     | 43/102 [00:03<00:04, 12.55RDM/s]     44%|████▍     | 45/102 [00:03<00:04, 12.54RDM/s]     46%|████▌     | 47/102 [00:04<00:04, 12.53RDM/s]     48%|████▊     | 49/102 [00:04<00:04, 12.53RDM/s]     50%|█████     | 51/102 [00:04<00:04, 12.55RDM/s]     52%|█████▏    | 53/102 [00:04<00:03, 12.53RDM/s]     54%|█████▍    | 55/102 [00:04<00:03, 12.55RDM/s]     56%|█████▌    | 57/102 [00:04<00:03, 12.57RDM/s]     58%|█████▊    | 59/102 [00:04<00:03, 12.56RDM/s]     60%|█████▉    | 61/102 [00:05<00:03, 12.57RDM/s]     62%|██████▏   | 63/102 [00:05<00:03, 12.59RDM/s]     64%|██████▎   | 65/102 [00:05<00:02, 12.60RDM/s]     66%|██████▌   | 67/102 [00:05<00:02, 12.60RDM/s]     68%|██████▊   | 69/102 [00:05<00:02, 12.60RDM/s]     70%|██████▉   | 71/102 [00:05<00:02, 12.45RDM/s]     72%|███████▏  | 73/102 [00:06<00:02, 12.43RDM/s]     74%|███████▎  | 75/102 [00:06<00:02, 12.43RDM/s]     75%|███████▌  | 77/102 [00:06<00:02, 12.39RDM/s]     77%|███████▋  | 79/102 [00:06<00:01, 12.39RDM/s]     79%|███████▉  | 81/102 [00:06<00:01, 12.39RDM/s]     81%|████████▏ | 83/102 [00:06<00:01, 12.38RDM/s]     83%|████████▎ | 85/102 [00:07<00:01, 12.41RDM/s]     85%|████████▌ | 87/102 [00:07<00:01, 12.45RDM/s]     87%|████████▋ | 89/102 [00:07<00:01, 12.46RDM/s]     89%|████████▉ | 91/102 [00:07<00:00, 12.44RDM/s]     91%|█████████ | 93/102 [00:07<00:00, 12.49RDM/s]     93%|█████████▎| 95/102 [00:07<00:00, 12.48RDM/s]     95%|█████████▌| 97/102 [00:08<00:00, 12.48RDM/s]     97%|█████████▋| 99/102 [00:08<00:00, 12.47RDM/s]     99%|█████████▉| 101/102 [00:08<00:00, 12.50RDM/s]    100%|██████████| 102/102 [00:08<00:00, 12.09RDM/s]

    <matplotlib.legend.Legend object at 0x7f7269af5910>




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 11.746 seconds)


.. _sphx_glr_download_auto_examples_core_plot_rsa_between_rdms.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_rsa_between_rdms.ipynb <plot_rsa_between_rdms.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_rsa_between_rdms.py <plot_rsa_between_rdms.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_rsa_between_rdms.zip <plot_rsa_between_rdms.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
