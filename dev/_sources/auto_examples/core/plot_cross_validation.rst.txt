
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/core/plot_cross_validation.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_core_plot_cross_validation.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_core_plot_cross_validation.py:


Using cross-validation when computing RDMs
------------------------------------------

This example demonstrates how to perform cross-validation when computing dissimilarity
matrices (RDMs). When the data has repeated measurements of the same stimulus type,
cross-validation can be used to provide much more robust distance estimates between
stimulus types. Repeated measurements can for example be actual repetitions of the same
stimulus within the same recording, or recordings on multiple volunteers with the same
stimuli.

The dataset will be the kiloword dataset [1]_: approximately 1,000 words were presented
to 75 participants in a go/no-go lexical decision task while event-related potentials
(ERPs) were recorded.

This dataset as provided does not have repeated measurements of the same stimuli. To
illustrate cross-validation, we will treat words with the same number of letters as
being repeated measurements of the same stimulus type.

.. [1] Dufau, S., Grainger, J., Midgley, KJ., Holcomb, PJ (2015). A thousand words are
       worth a picture: Snapshots of printed-word processing in an event-related
       potential megastudy. Psychological science.

| Authors:
| Marijn van Vliet <marijn.vanvliet@aalto.fi>

.. GENERATED FROM PYTHON SOURCE LINES 30-35

.. code-block:: Python


    # Import required packages
    import mne
    import mne_rsa








.. GENERATED FROM PYTHON SOURCE LINES 36-41

MNE-Python contains a built-in data loader for the kiloword dataset. We use it here to
read it as 960 epochs. Each epoch represents the brain response to a single word,
averaged across all the participants. For this example, we speed up the computation,
at a cost of temporal precision, by downsampling the data from the original 250 Hz. to
100 Hz.

.. GENERATED FROM PYTHON SOURCE LINES 41-47

.. code-block:: Python


    data_path = mne.datasets.kiloword.data_path(verbose=True)
    epochs = mne.read_epochs(data_path / "kword_metadata-epo.fif")
    epochs = epochs.resample(100)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Reading /home/runner/mne_data/MNE-kiloword-data/kword_metadata-epo.fif ...
    Isotrak not found
        Found the data of interest:
            t =    -100.00 ...     920.00 ms
            0 CTF compensation matrices available
    Adding metadata with 8 columns
    960 matching events found
    No baseline correction applied
    0 projection items activated




.. GENERATED FROM PYTHON SOURCE LINES 48-51

The ``epochs`` object contains a ``.metadata`` field that contains information about
the 960 words that were used in the experiment. Let's have a look at the metadata for
the 10 random words:

.. GENERATED FROM PYTHON SOURCE LINES 51-55

.. code-block:: Python


    epochs.metadata.sample(10)







.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>WORD</th>
          <th>Concreteness</th>
          <th>WordFrequency</th>
          <th>OrthographicDistance</th>
          <th>NumberOfLetters</th>
          <th>BigramFrequency</th>
          <th>ConsonantVowelProportion</th>
          <th>VisualComplexity</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>7</th>
          <td>land</td>
          <td>5.4000</td>
          <td>3.648945</td>
          <td>1.20</td>
          <td>4.0</td>
          <td>757.500000</td>
          <td>0.750000</td>
          <td>65.601033</td>
        </tr>
        <tr>
          <th>837</th>
          <td>symbol</td>
          <td>2.8000</td>
          <td>2.624282</td>
          <td>2.75</td>
          <td>6.0</td>
          <td>212.000000</td>
          <td>0.666667</td>
          <td>70.563481</td>
        </tr>
        <tr>
          <th>348</th>
          <td>marine</td>
          <td>4.9000</td>
          <td>2.264818</td>
          <td>1.70</td>
          <td>6.0</td>
          <td>1021.000000</td>
          <td>0.500000</td>
          <td>66.202881</td>
        </tr>
        <tr>
          <th>602</th>
          <td>clergy</td>
          <td>5.0000</td>
          <td>1.934498</td>
          <td>2.50</td>
          <td>6.0</td>
          <td>356.666667</td>
          <td>0.666667</td>
          <td>64.024348</td>
        </tr>
        <tr>
          <th>555</th>
          <td>quest</td>
          <td>3.8500</td>
          <td>2.064458</td>
          <td>1.95</td>
          <td>5.0</td>
          <td>351.600000</td>
          <td>0.600000</td>
          <td>69.082596</td>
        </tr>
        <tr>
          <th>518</th>
          <td>blob</td>
          <td>4.3500</td>
          <td>1.491362</td>
          <td>1.65</td>
          <td>4.0</td>
          <td>314.500000</td>
          <td>0.750000</td>
          <td>69.175876</td>
        </tr>
        <tr>
          <th>633</th>
          <td>outside</td>
          <td>3.5000</td>
          <td>3.341632</td>
          <td>2.20</td>
          <td>7.0</td>
          <td>351.142857</td>
          <td>0.428571</td>
          <td>65.254569</td>
        </tr>
        <tr>
          <th>681</th>
          <td>original</td>
          <td>3.3000</td>
          <td>3.182985</td>
          <td>2.55</td>
          <td>8.0</td>
          <td>650.375000</td>
          <td>0.500000</td>
          <td>58.489999</td>
        </tr>
        <tr>
          <th>297</th>
          <td>wrong</td>
          <td>2.2000</td>
          <td>3.488410</td>
          <td>1.85</td>
          <td>5.0</td>
          <td>475.800000</td>
          <td>0.800000</td>
          <td>74.185408</td>
        </tr>
        <tr>
          <th>44</th>
          <td>slat</td>
          <td>5.0625</td>
          <td>0.301030</td>
          <td>1.00</td>
          <td>4.0</td>
          <td>531.000000</td>
          <td>0.750000</td>
          <td>57.967217</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 56-64

The kiloword dataset as provided does not have repeated measurements of the same
stimuli. To illustrate cross-validation, we will treat words with the same number of
letters as being repeated measurements of the same stimulus type.

To denote which epochs are repetitions of the same stimulus, we create a list
``labels`` that contains a label for each epoch indicating to which stimulus it
belongs. Repetitions of the same stimulus need to have the same label, hence we will
use the ``NumberOfLetters`` field of the metadata as label.

.. GENERATED FROM PYTHON SOURCE LINES 64-68

.. code-block:: Python


    labels = epochs.metadata.NumberOfLetters.astype(int)









.. GENERATED FROM PYTHON SOURCE LINES 69-73

Many high-level functions in the MNE-RSA module can take the ``y`` list as a parameter
to enable cross-validation. Notably the functions for performing RSA and computing
RDMs. In this example, we will restrict the analysis to computing RDMs using a
spatio-temporal searchlight on the sensor-level data.

.. GENERATED FROM PYTHON SOURCE LINES 73-87

.. code-block:: Python


    rdms = mne_rsa.rdm_epochs(
        epochs,  # The EEG data
        labels=labels,  # Set labels to enable cross validation
        n_folds=5,  # Number of folds to use during cross validation
        dist_metric="sqeuclidean",  # Distance metric to compute the RDMs
        spatial_radius=0.45,  # Spatial radius of the searchlight patch in meters.
        temporal_radius=0.05,  # Temporal radius of the searchlight path in seconds.
        tmin=0.15,
        tmax=0.25,
        n_jobs=1,  # Use this to specify the number of CPU cores to use.
    )  # To save time, only analyze this time interval









.. GENERATED FROM PYTHON SOURCE LINES 88-89

Plotting the cross-validated RDMs

.. GENERATED FROM PYTHON SOURCE LINES 89-93

.. code-block:: Python


    mne_rsa.plot_rdms_topo(rdms, epochs.info)





.. image-sg:: /auto_examples/core/images/sphx_glr_plot_cross_validation_001.png
   :alt: Time point: 0
   :srcset: /auto_examples/core/images/sphx_glr_plot_cross_validation_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Creating spatio-temporal searchlight patches

    <Figure size 640x480 with 29 Axes>



.. GENERATED FROM PYTHON SOURCE LINES 94-97

For performance reasons, the low-level functions of MNE-RSA do not take a ``y`` list
for cross-validation. Instead, they require the data to be already split into folds.
The :func:`mne_rsa.create_folds` function can create these folds.

.. GENERATED FROM PYTHON SOURCE LINES 97-104

.. code-block:: Python


    X = epochs.get_data()
    y = epochs.metadata.NumberOfLetters.astype(int)
    folds = mne_rsa.create_folds(X, y, n_folds=5)

    rdm = mne_rsa.compute_rdm_cv(folds, metric="euclidean")
    mne_rsa.plot_rdms(rdm)



.. image-sg:: /auto_examples/core/images/sphx_glr_plot_cross_validation_002.png
   :alt: plot cross validation
   :srcset: /auto_examples/core/images/sphx_glr_plot_cross_validation_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <Figure size 200x200 with 2 Axes>




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 2.667 seconds)


.. _sphx_glr_download_auto_examples_core_plot_cross_validation.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_cross_validation.ipynb <plot_cross_validation.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_cross_validation.py <plot_cross_validation.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_cross_validation.zip <plot_cross_validation.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
